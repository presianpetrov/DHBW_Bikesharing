{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json, os\n",
    "import pandas as pd\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filenames(path):\n",
    "    \"\"\"\n",
    "    get file names from json folder to derive with data and timestamp\n",
    "    \"\"\"\n",
    "    files = os.listdir(path)\n",
    "    files_lst = []\n",
    "    for f in files:\n",
    "        dt = (f[13:21])\n",
    "        tm = (f[22:28])\n",
    "        dat = (f,dt,tm)\n",
    "        files_lst.append(dat)\n",
    "    return(files_lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_json(file):\n",
    "    with open(r'./json/'+file[0]) as f:\n",
    "        json_data = json.load(f)\n",
    "    return json_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def json_extract(json_data,i,col1,col2):\n",
    "    parsed1 = json_data['countries'][0]['cities'][0]['places'][i][col1]\n",
    "    parsed2 = json_data['countries'][0]['cities'][0]['places'][i][col2]\n",
    "    return parsed1,parsed2  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unpacking_bike_numbers(column):\n",
    "    \"\"\" \n",
    "    getting unique list of bikes\n",
    "    \"\"\"\n",
    "    bike_unpack = pd.DataFrame(df[column].tolist(), index=df.index)\n",
    "    colnames = list(bike_unpack.columns.values)\n",
    "    all_bikes = []\n",
    "    all_bikes = bike_unpack[0]\n",
    "    \n",
    "    for c in colnames:\n",
    "        data= bike_unpack[c]\n",
    "        pd.concat([all_bikes,data])\n",
    "    all_bikes = all_bikes.unique()\n",
    "    return all_bikes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trips_by_bike(df):\n",
    "    \"\"\" generating state for each bike\"\"\" \n",
    "    pd.options.mode.chained_assignment = None  # default='warn'\n",
    "    appended_data = []\n",
    "    for b in all_bikes:\n",
    "        data = df[df[\"bike_numbers\"].apply(lambda x: True if b in x else False)]\n",
    "        data.groupby(['from_station']).size()\n",
    "        data['bike_id'] = b\n",
    "        # min and max time for this bike on one station\n",
    "        data['dt_end'] = data.groupby('from_station')['date_time'].transform('max')\n",
    "        data['dt_start'] = data.groupby('from_station')['date_time'].transform('min')\n",
    "        data= data[['bike_id','from_station','from_lat','from_long','from_station_id',\n",
    "                    'from_station_mode','dt_start','dt_end']].copy()\n",
    "        appended_data.append(data)\n",
    "    return appended_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generating_duration(df):\n",
    "    df = df.sort_values(['bike_id','dt_start'], ascending=True)\n",
    "    df['bike_next_row'] = df['bike_id'].shift(-1)\n",
    "    df['dt_min_next_row'] = df['dt_start'].shift(-1)\n",
    "    df['station_next_row'] = df['from_station'].shift(-1)\n",
    "    df['station_id_next_row'] = df['from_station_id'].shift(-1)\n",
    "    df['trip_duration'] = np.nan\n",
    "    df['trip_end_time'] = np.nan\n",
    "    df['trip_end_time'] = df['trip_end_time'].astype('datetime64[s]')\n",
    "    df['diff'] = (df['dt_min_next_row']-df['dt_end']).astype('timedelta64[s]')\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generating_next_station(df):\n",
    "    df['station_mode_next_row'] = df['from_station_mode'].shift(-1)\n",
    "    df['lat_next_row'] = df['from_lat'].shift(-1)\n",
    "    df['long_next_row'] = df['from_long'].shift(-1)\n",
    "    df['to_station'] = np.nan\n",
    "    df['to_station_id'] = np.nan\n",
    "    df['to_station_mode'] = np.nan\n",
    "    df['to_lat'] = np.nan\n",
    "    df['to_long'] = np.nan\n",
    "    trips = df.drop_duplicates(subset=['bike_id','from_station'], keep='last')\n",
    "    return trips"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generating_destination(trips):\n",
    "    trips.loc[((trips['bike_id'] == trips['bike_next_row'])\n",
    "              & (trips['dt_min_next_row'] > trips['dt_start'])), \n",
    "             'trip_end_time'] = trips['dt_min_next_row']\n",
    "    trips.loc[((trips['bike_id'] == trips['bike_next_row'])\n",
    "              & (trips['dt_min_next_row'] > trips['dt_start'])), \n",
    "             'to_station'] = trips['station_next_row']\n",
    "    trips.loc[((trips['bike_id'] == trips['bike_next_row'])\n",
    "              & (trips['dt_min_next_row'] > trips['dt_start'])), \n",
    "             'to_station_id'] = trips['station_id_next_row']\n",
    "    trips.loc[((trips['bike_id'] == trips['bike_next_row'])\n",
    "              & (trips['dt_min_next_row'] > trips['dt_start'])), \n",
    "             'to_station_mode'] = trips['station_mode_next_row']\n",
    "    trips.loc[((trips['bike_id'] == trips['bike_next_row'])\n",
    "              & (trips['dt_min_next_row'] > trips['dt_start'])), \n",
    "             'to_lat'] = trips['lat_next_row']\n",
    "    trips.loc[((trips['bike_id'] == trips['bike_next_row'])\n",
    "              & (trips['dt_min_next_row'] > trips['dt_start'])), \n",
    "             'to_long'] = trips['long_next_row']\n",
    "    trips.loc[((trips['bike_id'] == trips['bike_next_row'])\n",
    "              & (trips['dt_min_next_row'] > trips['dt_start'])), \n",
    "             'trip_duration'] = trips['diff']\n",
    "    return trips"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trip_ids(df, day):\n",
    "    newindex = np.arange(int(day)*1000, int(day)*1000+len(df.index), 1)\n",
    "    df['trip_id'] = newindex\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bike_lst = []\n",
    "df_files = pd.DataFrame(filenames(r'./json/'),\n",
    "                   columns=('file','day','time'))\n",
    "day = df_files.groupby(by=('day')).size()\n",
    "day.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "list indices must be integers or slices, not str",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[17], line 11\u001b[0m\n\u001b[0;32m      9\u001b[0m num_places \u001b[38;5;241m=\u001b[39m json_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcountries\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcities\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnum_places\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m     10\u001b[0m refresh_rate \u001b[38;5;241m=\u001b[39m json_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcountries\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcities\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrefresh_rate\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m---> 11\u001b[0m uid, name \u001b[38;5;241m=\u001b[39m \u001b[43mjson_extract\u001b[49m\u001b[43m(\u001b[49m\u001b[43mjson_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43muid\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mname\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     12\u001b[0m lat, lng \u001b[38;5;241m=\u001b[39m json_extract(json_data,i,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlat\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlng\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     13\u001b[0m bikes, booked_bikes \u001b[38;5;241m=\u001b[39m json_extract(json_data,i,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbikes\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbooked_bikes\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "Cell \u001b[1;32mIn[4], line 2\u001b[0m, in \u001b[0;36mjson_extract\u001b[1;34m(json_data, i, col1, col2)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mjson_extract\u001b[39m(json_data,i,col1,col2):\n\u001b[1;32m----> 2\u001b[0m     parsed1 \u001b[38;5;241m=\u001b[39m \u001b[43mjson_data\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcountries\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcities\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mplaces\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m[col1]\n\u001b[0;32m      3\u001b[0m     parsed2 \u001b[38;5;241m=\u001b[39m json_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcountries\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcities\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mplaces\u001b[39m\u001b[38;5;124m'\u001b[39m][i][col2]\n\u001b[0;32m      4\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parsed1,parsed2\n",
      "\u001b[1;31mTypeError\u001b[0m: list indices must be integers or slices, not str"
     ]
    }
   ],
   "source": [
    "for i in day.reset_index()[\"day\"]:\n",
    "    singleday = df_files[(df_files['day'] == i) ]\n",
    "    singleday = singleday.values.tolist()\n",
    "\n",
    "    for f in singleday:\n",
    "        json_data = parse_json(f)\n",
    "        for n in range(0,3000):\n",
    "            avail_bikes = json_data['countries'][0]['cities'][0]['available_bikes']\n",
    "            num_places = json_data['countries'][0]['cities'][0]['num_places']\n",
    "            refresh_rate = json_data['countries'][0]['cities'][0]['refresh_rate']\n",
    "            uid, name = json_extract(json_data,i,'uid','name')\n",
    "            lat, lng = json_extract(json_data,i,'lat','lng')\n",
    "            bikes, booked_bikes = json_extract(json_data,i,'bikes','booked_bikes')\n",
    "            free_racks, bike_racks = json_extract(json_data,i,'free_racks','bike_racks') \n",
    "            terminal_type, spot = json_extract(json_data,i,'terminal_type','spot') \n",
    "            if spot==True:\n",
    "                spot='station'\n",
    "            else:\n",
    "                spot='floating'           \n",
    "            bike_numbers, number = json_extract(json_data,i,'bike_numbers','number') \n",
    "\n",
    "            bike_data = (datetime.strptime((f[1] +' '+ f[2]), \"%Y%m%d %H%M%S\"),\n",
    "                        refresh_rate,num_places,avail_bikes,uid,lat,lng,name,\n",
    "                        number,bikes,booked_bikes,free_racks,bike_racks,terminal_type,\n",
    "                        spot,bike_numbers)\n",
    "            bike_lst.append(bike_data)\n",
    "            print(bike_lst)\n",
    "\n",
    "    \n",
    "    colnames = ('date_time','refresh_rate','num_places','total_avail_bikes','uid','from_lat',\n",
    "    'from_long','from_station','from_station_id','bikes','booked_bikes','free_racks',\n",
    "    'bike_racks','terminal_type','from_station_mode','bike_numbers')\n",
    "    \n",
    "    df = pd.DataFrame(bike_lst, columns = colnames)\n",
    "    \n",
    "    \n",
    "    all_bikes = unpacking_bike_numbers('bike_numbers')\n",
    "    appended_data = trips_by_bike(df)\n",
    "    trips = pd.concat(appended_data,ignore_index=True)\n",
    "    trips = generating_duration(trips)\n",
    "    trips = generating_next_station(trips)\n",
    "    trips = generating_destination(trips)\n",
    "\n",
    "    trips = trip_ids(trips, singleday[0][1])\n",
    "    df_trip = trips[['trip_id','bike_id','trip_duration','dt_end','trip_end_time',\n",
    "    'from_station','from_station_id','from_station_mode','from_lat','from_long',\n",
    "    'to_station','to_station_id','to_station_mode','to_lat','to_long'\n",
    "    ]]\n",
    "    df_trip = df_trip.rename(columns = {'dt_end':'trip_start_time'})\n",
    "    df_trip.to_csv(f'trips/trips_{i}.csv')   "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
